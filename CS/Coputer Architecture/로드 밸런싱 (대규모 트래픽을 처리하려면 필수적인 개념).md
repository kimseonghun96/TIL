# 로드 밸런싱 (대규모 트래픽을 처리하려면 필수적인 개념)

> 둘 이상의 CPU or 저장장치와 같은 컴퓨터 자원들에게 작업을 나누는 것

**로드(Load) = 서버가 받는 부하 (트래픽)**

요즘 시대에는 웹사이트에 접속하는 인원이 급격히 늘어나게 되었다.

따라서 이 사람들에 대해 모든 트래픽을 감당하기엔 1대의 서버로는 부족하다. 대응 방안으로 하드웨어의 성능을 올리거나(Scale-up) 여러대의 서버가 나눠서 일하도록 만드는 것(Scale-out)이 있다.

하드웨어 향상 비용이 더욱 비싸기도 하고, 서버가 여러대면 무중단 서비스를 제공하는 환경 구성이 용이하므로 Scale-out이 효과적이다. 이때 여러 서버에게 균등하게 트래픽을 분산시켜주는 것이 바로 **로드 밸런싱**이다.

**로드 밸런싱**은 분산식 웹 서비스로, 여러 서버에 부하(Load)를 나누어주는 역할을 한다. Load Balancer를 클라이언트와 서버 사이에 두고, 부하가 일어나지 않도록 여러 서버에 분산시켜주는 방식이다. 서비스를 운영하는 사이트의 규모에 따라 웹 서버를 추가로 증설하면서 로드 밸런서로 관리해주면 웹 서버의 부하를 해결할 수 있다.

→ 하나의 인터넷 서비스가 발생하는 트래픽이 많을 때 여러 대의 서버가 **분산처리**하여 서버의 로드율 증가, 부하량, 속도저하 등을 고려하여 적절히 분산처리하여 해결해주는 서비스입니다.

### 트래픽이 늘어났을 때 해결하는 방법

1. Scale-Up : 서버 자체의 퍼포먼스를 늘리는 방법 (하드웨어 성능을 올린다. )
   
   1. 4GB의 RAM을 32GB로 늘리거나
   2. CPU를 업그레이드 하거나

2. Scale-Out : 하나의 Server 보다는 여러 대의 Sever가 나눠서 일을 한다.
   
   1. 가격이 더 나가긴 하지만 한대로 처리할 수 있는 걸 세대, 네대로 늘리는 것 → 분산시스템 구축 → 이때 중요한 개념이 로드 벨런싱 (서버를 여러대 가지고 있기 때문에 들어오는 트래픽을 분산해줄 모듈이 필요해짐 )

### **[#](https://gyoogle.dev/blog/computer-science/network/Load%20Balancing.html#%E1%84%85%E1%85%A9%E1%84%83%E1%85%B3-%E1%84%87%E1%85%A2%E1%86%AF%E1%84%85%E1%85%A5%E1%86%AB%E1%84%89%E1%85%A5%E1%84%80%E1%85%A1-%E1%84%89%E1%85%A5%E1%84%87%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF-%E1%84%89%E1%85%A5%E1%86%AB%E1%84%90%E1%85%A2%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB-%E1%84%87%E1%85%A1%E1%86%BC%E1%84%89%E1%85%B5%E1%86%A8)로드 밸런서가 서버를 선택하는 방식**

- **라운드 로빈(Round Robin)** : CPU 스케줄링의 라운드 로빈 방식 활용
  
  - 여러 대의 서버가 있을 때 들어오는 리퀘스트를 그 서버들에 순차적으로 하나씩 보내는 방법
  - 트래픽을 모든 서버가 골고루 분산하여 가져감
  
  ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/508e4892-0806-4de8-bdcd-6846439ea664/08c5d272-18ed-4d32-9ef4-2bd76bab1a9b/Untitled.png)

- **RANDOM SELECT** : 리퀘스트가 들어왔을 때 로드 벨런서가 랜덤으로 아무서버에 리퀘스트를 보내는 방법 → 구현이 쉽다.
  
  ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/508e4892-0806-4de8-bdcd-6846439ea664/a615f6e6-85c0-43d7-8b46-521a83e4327d/Untitled.png)

- **Least Connections** : 연결 개수가 가장 적은 서버 선택 (트래픽으로 인해 세션이 길어지는 경우 권장)
  
  - 어플리케이션 서버가 로드 밸런서에게 얼마만큼의 트래픽 가지고있고 얼마만큼의 커넥션을 맺고 있는지 역으로 알려주는 것
  - 서버와 로드 밸런서 간에 실시간 통신이 이뤄져야함
  
  ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/508e4892-0806-4de8-bdcd-6846439ea664/c571e037-f3cb-4744-a3d8-27328a199ff7/Untitled.png)

- Source : 사용자 IP를 해싱하여 분배 (특정 사용자가 항상 같은 서버로 연결되는 것 보장)

### 로드밸런싱을 구현하는 방법

1. 소프트웨어적 방식 - 로직을 구현해서 트래픽을 분산시키 방법
   
   1. HAProxy, Reverse Proxy(Nginx, Apache…)와 같은 웹 서버를 이용해서 거기에 구현된 기능을 가지고 로드 밸런싱을 할 수 있다.
   
   → 장점 : 로직만 구현하면 되기 때문에 저렴하다.

2. 하드웨어적 방식 : 물리적으로 서버를 묶는 것
   
   1. L4 스위치, L7 스위치를 사용해서 데이터센터에서 직접 물리적인 방법으로 서버들을 묶는 방법
   
   → 장점 :
   
   - 물리적인 방식으로 서버를 묶기때문에 안정적이다.
   - IDC(데이터 센터)에서 묶는 작업을 하기때문에 안정성이 높다. (아무나 IDC에 출입 x)

### **[#](https://gyoogle.dev/blog/computer-science/network/Load%20Balancing.html#%E1%84%85%E1%85%A9%E1%84%83%E1%85%B3-%E1%84%87%E1%85%A2%E1%86%AF%E1%84%85%E1%85%A5%E1%86%AB%E1%84%89%E1%85%A5-%E1%84%8C%E1%85%A1%E1%86%BC%E1%84%8B%E1%85%A2-%E1%84%83%E1%85%A2%E1%84%87%E1%85%B5)로드 밸런서 장애 대비**

- 로드 밸런서가 죽으면 서비스가 죽는 것
  
  → 특정 포인트 (로드 밸런서)에서 에러가 났을 경우 전체 시스템이 다운되는 경우를 SPOF(Single Point of Failure)라고 부른다.
  
  → 그래서 로드 밸런서도 Scale-Out할 필요가 있다.
  
  ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/508e4892-0806-4de8-bdcd-6846439ea664/679955d8-faba-4e9b-bcdc-026c21682839/Untitled.png)

서버를 분배하는 로드 밸런서에 문제가 생길 수 있기 때문에 로드 밸런서를 이중화하여 대비한다.

[로드 밸런서(Load Balancer)란?](https://nesoy.github.io/articles/2018-06/Load-Balancer)
